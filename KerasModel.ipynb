{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spa.txt\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    text_pairs.append((eng, spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I will be busy this afternoon.', '[start] Voy a estar ocupada esta tarde. [end]')\n",
      "('Tom kicked the stool out from under Mary.', '[start] Tom sacó el taburete situado bajo Mary. [end]')\n",
      "('They got married last fall.', '[start] Ellos se casaron el otoño pasado. [end]')\n",
      "('I quit.', '[start] Renuncié. [end]')\n",
      "('Can I leave my bag here?', '[start] ¿Puedo dejar aquí mi bolsa? [end]')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "83276 training pairs\n",
      "17844 validation pairs\n",
      "17844 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "spa_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_spa_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "spa_vectorization.adapt(train_spa_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, spa):\n",
    "    eng = eng_vectorization(eng)\n",
    "    spa = spa_vectorization(spa)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": eng,\n",
    "            \"decoder_inputs\": spa[:, :-1],\n",
    "        },\n",
    "        spa[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 03:30:27.541270: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.ops as ops\n",
    "\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"dense_dim\": self.dense_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = ops.shape(inputs)[-1]\n",
    "        positions = ops.arange(0, length, 1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        inputs, encoder_outputs = inputs\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        if mask is None:\n",
    "            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n",
    "        else:\n",
    "            inputs_padding_mask, encoder_outputs_padding_mask = mask\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask,\n",
    "            query_mask=inputs_padding_mask,\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            query_mask=inputs_padding_mask,\n",
    "            key_mask=encoder_outputs_padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = ops.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = ops.arange(sequence_length)[:, None]\n",
    "        j = ops.arange(sequence_length)\n",
    "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
    "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = ops.concatenate(\n",
    "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
    "            axis=0,\n",
    "        )\n",
    "        return ops.tile(mask, mult)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"latent_dim\": self.latent_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "transformer = keras.Model(\n",
    "    {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
    "    decoder_outputs,\n",
    "    name=\"transformer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3651s\u001b[0m 3s/step - accuracy: 0.1039 - loss: 5.0816 - val_accuracy: 0.1923 - val_loss: 2.8835\n",
      "Epoch 2/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 1s/step - accuracy: 0.1934 - loss: 2.9256 - val_accuracy: 0.2139 - val_loss: 2.4467\n",
      "Epoch 3/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3760s\u001b[0m 3s/step - accuracy: 0.2148 - loss: 2.4805 - val_accuracy: 0.2211 - val_loss: 2.3595\n",
      "Epoch 4/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1785s\u001b[0m 1s/step - accuracy: 0.2247 - loss: 2.2845 - val_accuracy: 0.2267 - val_loss: 2.2260\n",
      "Epoch 5/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m830s\u001b[0m 638ms/step - accuracy: 0.2322 - loss: 2.1607 - val_accuracy: 0.2276 - val_loss: 2.2172\n",
      "Epoch 6/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m883s\u001b[0m 678ms/step - accuracy: 0.2367 - loss: 2.0940 - val_accuracy: 0.2312 - val_loss: 2.1930\n",
      "Epoch 7/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m897s\u001b[0m 689ms/step - accuracy: 0.2413 - loss: 2.0305 - val_accuracy: 0.2293 - val_loss: 2.2400\n",
      "Epoch 8/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 704ms/step - accuracy: 0.2439 - loss: 1.9848 - val_accuracy: 0.2323 - val_loss: 2.2236\n",
      "Epoch 9/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 704ms/step - accuracy: 0.2469 - loss: 1.9477 - val_accuracy: 0.2329 - val_loss: 2.2399\n",
      "Epoch 10/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m905s\u001b[0m 695ms/step - accuracy: 0.2504 - loss: 1.9123 - val_accuracy: 0.2319 - val_loss: 2.2525\n",
      "Epoch 11/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m907s\u001b[0m 697ms/step - accuracy: 0.2510 - loss: 1.8841 - val_accuracy: 0.2327 - val_loss: 2.2914\n",
      "Epoch 12/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m945s\u001b[0m 726ms/step - accuracy: 0.2529 - loss: 1.8563 - val_accuracy: 0.2314 - val_loss: 2.3239\n",
      "Epoch 13/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 2s/step - accuracy: 0.2545 - loss: 1.8311 - val_accuracy: 0.2324 - val_loss: 2.3024\n",
      "Epoch 14/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 630ms/step - accuracy: 0.2571 - loss: 1.7970 - val_accuracy: 0.2319 - val_loss: 2.3387\n",
      "Epoch 15/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m806s\u001b[0m 619ms/step - accuracy: 0.2580 - loss: 1.7942 - val_accuracy: 0.2329 - val_loss: 2.3424\n",
      "Epoch 16/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 512ms/step - accuracy: 0.2589 - loss: 1.7698 - val_accuracy: 0.2328 - val_loss: 2.3674\n",
      "Epoch 17/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 508ms/step - accuracy: 0.2599 - loss: 1.7423 - val_accuracy: 0.2342 - val_loss: 2.3856\n",
      "Epoch 18/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 506ms/step - accuracy: 0.2625 - loss: 1.7234 - val_accuracy: 0.2344 - val_loss: 2.3804\n",
      "Epoch 19/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2182s\u001b[0m 2s/step - accuracy: 0.2637 - loss: 1.6998 - val_accuracy: 0.2328 - val_loss: 2.4096\n",
      "Epoch 20/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 510ms/step - accuracy: 0.2650 - loss: 1.6895 - val_accuracy: 0.2330 - val_loss: 2.4376\n",
      "Epoch 21/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 502ms/step - accuracy: 0.2663 - loss: 1.6727 - val_accuracy: 0.2344 - val_loss: 2.4551\n",
      "Epoch 22/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 511ms/step - accuracy: 0.2666 - loss: 1.6633 - val_accuracy: 0.2339 - val_loss: 2.4708\n",
      "Epoch 23/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 478ms/step - accuracy: 0.2679 - loss: 1.6424 - val_accuracy: 0.2340 - val_loss: 2.4909\n",
      "Epoch 24/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 481ms/step - accuracy: 0.2690 - loss: 1.6269 - val_accuracy: 0.2336 - val_loss: 2.4873\n",
      "Epoch 25/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 498ms/step - accuracy: 0.2703 - loss: 1.6177 - val_accuracy: 0.2339 - val_loss: 2.4975\n",
      "Epoch 26/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 489ms/step - accuracy: 0.2712 - loss: 1.5838 - val_accuracy: 0.2319 - val_loss: 2.5470\n",
      "Epoch 27/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 489ms/step - accuracy: 0.2716 - loss: 1.5816 - val_accuracy: 0.2346 - val_loss: 2.5156\n",
      "Epoch 28/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 970ms/step - accuracy: 0.2728 - loss: 1.5706 - val_accuracy: 0.2337 - val_loss: 2.5763\n",
      "Epoch 29/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1737s\u001b[0m 1s/step - accuracy: 0.2726 - loss: 1.5647 - val_accuracy: 0.2344 - val_loss: 2.5767\n",
      "Epoch 30/30\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 732ms/step - accuracy: 0.2745 - loss: 1.5489 - val_accuracy: 0.2337 - val_loss: 2.6143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x178789ad0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30  # This should be at least 30 for convergence\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kaushalchamarthy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG: He can't speak English, can he?\n",
      "OUT: [start] Él no sabe hablar inglés [end]\n",
      "REF: [start] ¿Él no puede hablar inglés, no es así? [end]\n",
      "BLEU: 0.4639 | Adjusted Score: 0.6774\n",
      "------------------------------------------------------------\n",
      "ENG: It's one of those moments.\n",
      "OUT: [start] es uno de esos últimos [end]\n",
      "REF: [start] Es uno de esos momentos. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Does Tom still live in Boston?\n",
      "OUT: [start] tom todavía vive en boston [end]\n",
      "REF: [start] ¿Tom todavía vive en Boston? [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: During warm weather, sweating helps man regulate his body temperature.\n",
      "OUT: [start] cuando clima caliente le [UNK] el hombre se [UNK] bien su temperatura [end]\n",
      "REF: [start] Durante tiempo calurosos, sudar ayuda al hombre a regular su temperatura corporal. [end]\n",
      "BLEU: 0.3587 | Adjusted Score: 0.5532\n",
      "------------------------------------------------------------\n",
      "ENG: We often eat raw fish.\n",
      "OUT: [start] a menudo a menudo a peces peces peces [end]\n",
      "REF: [start] Nosotros comemos pescado crudo con frecuencia. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.4096\n",
      "------------------------------------------------------------\n",
      "ENG: There comes the bus.\n",
      "OUT: [start] hay el autobús [end]\n",
      "REF: [start] Ahí viene el bus. [end]\n",
      "BLEU: 0.3117 | Adjusted Score: 0.4516\n",
      "------------------------------------------------------------\n",
      "ENG: Tom is waiting for you inside.\n",
      "OUT: [start] tom te está esperando dentro [end]\n",
      "REF: [start] Tom te está esperando adentro. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Take off your socks, please.\n",
      "OUT: [start] por favor toma los calcetines [end]\n",
      "REF: [start] Por favor, quítese los calcetines. [end]\n",
      "BLEU: 0.8453 | Adjusted Score: 0.8453\n",
      "------------------------------------------------------------\n",
      "ENG: Tom chose the restaurant where we ate lunch.\n",
      "OUT: [start] tom recogió el restaurante en el que nos comí [end]\n",
      "REF: [start] Tom escogió el restaurante en el que almorzamos. [end]\n",
      "BLEU: 0.8342 | Adjusted Score: 0.8342\n",
      "------------------------------------------------------------\n",
      "ENG: Does Tom still live in Boston?\n",
      "OUT: [start] tom todavía vive en boston [end]\n",
      "REF: [start] ¿Tom todavía vive en Boston? [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: She asked him to open the window.\n",
      "OUT: [start] le pidió que abre la ventana abierta [end]\n",
      "REF: [start] Ella le pidió que abriera la ventana. [end]\n",
      "BLEU: 0.8257 | Adjusted Score: 0.8257\n",
      "------------------------------------------------------------\n",
      "ENG: I want to eat a mango.\n",
      "OUT: [start] quiero comer un [UNK] [end]\n",
      "REF: [start] Quiero comer un mango. [end]\n",
      "BLEU: 0.9045 | Adjusted Score: 0.9045\n",
      "------------------------------------------------------------\n",
      "ENG: I have a lot of cameras.\n",
      "OUT: [start] tengo muchas condiciones [end]\n",
      "REF: [start] Tengo muchas cámaras. [end]\n",
      "BLEU: 0.7888 | Adjusted Score: 0.7888\n",
      "------------------------------------------------------------\n",
      "ENG: I will follow your advice.\n",
      "OUT: [start] voy a seguir tu consejo [end]\n",
      "REF: [start] Voy a seguir vuestro consejo. [end]\n",
      "BLEU: 0.8875 | Adjusted Score: 0.8875\n",
      "------------------------------------------------------------\n",
      "ENG: I closed the door quietly so I wouldn't wake the baby up.\n",
      "OUT: [start] dejé las tareas en la puerta y no un bebé ni se [UNK] [end]\n",
      "REF: [start] Cerré suavemente la puerta para no despertar al bebé. [end]\n",
      "BLEU: 0.4448 | Adjusted Score: 0.5600\n",
      "------------------------------------------------------------\n",
      "ENG: I know Tom misses you.\n",
      "OUT: [start] sé que tom te va lo feo [end]\n",
      "REF: [start] Sé que Tom te extraña. [end]\n",
      "BLEU: 0.7826 | Adjusted Score: 0.7826\n",
      "------------------------------------------------------------\n",
      "ENG: I'm pleased you still remember.\n",
      "OUT: [start] estoy seguro de que todavía te recuerdo [end]\n",
      "REF: [start] Estoy satisfecho que tú todavía recuerdes. [end]\n",
      "BLEU: 0.4639 | Adjusted Score: 0.6914\n",
      "------------------------------------------------------------\n",
      "ENG: You deserve to succeed.\n",
      "OUT: [start] tú mereces triunfar [end]\n",
      "REF: [start] Mereces triunfar. [end]\n",
      "BLEU: 0.9444 | Adjusted Score: 0.9444\n",
      "------------------------------------------------------------\n",
      "ENG: Tom will catch Mary.\n",
      "OUT: [start] tom le va a mary [end]\n",
      "REF: [start] Tom cogerá a Mary. [end]\n",
      "BLEU: 0.6458 | Adjusted Score: 0.6458\n",
      "------------------------------------------------------------\n",
      "ENG: They say that I'm an old woman.\n",
      "OUT: [start] dicen que soy una anciana [end]\n",
      "REF: [start] Dicen que soy una vieja. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Please don't leave me alone.\n",
      "OUT: [start] por favor no me dejes solo [end]\n",
      "REF: [start] No me dejes sola, por favor. [end]\n",
      "BLEU: 0.9311 | Adjusted Score: 0.9311\n",
      "------------------------------------------------------------\n",
      "ENG: Tom has a way with words.\n",
      "OUT: [start] tom tiene muchas palabras [end]\n",
      "REF: [start] Tom se maneja con las palabras. [end]\n",
      "BLEU: 0.3077 | Adjusted Score: 0.6786\n",
      "------------------------------------------------------------\n",
      "ENG: That material's going to shrink if it's washed.\n",
      "OUT: [start] eso [UNK] de [UNK] en el año [end]\n",
      "REF: [start] Esa tela va a encoger si se lava. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.4314\n",
      "------------------------------------------------------------\n",
      "ENG: He is different from his older brother.\n",
      "OUT: [start] Él es diferente de su hermano mayor [end]\n",
      "REF: [start] Él es diferente de su hermano mayor. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Have you ever climbed Mount Everest?\n",
      "OUT: [start] has habido el everest el everest alguna vez [end]\n",
      "REF: [start] ¿Alguna vez has escalado el Monte Everest? [end]\n",
      "BLEU: 0.6093 | Adjusted Score: 0.6093\n",
      "------------------------------------------------------------\n",
      "ENG: Tom's alive.\n",
      "OUT: [start] tom está vivo [end]\n",
      "REF: [start] Tom está vivo. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: This is exactly what I've been looking for.\n",
      "OUT: [start] esto es exactamente lo que he estado buscando [end]\n",
      "REF: [start] Esto es exactamente lo que estaba buscando. [end]\n",
      "BLEU: 0.9128 | Adjusted Score: 0.9128\n",
      "------------------------------------------------------------\n",
      "ENG: Where will you be on Monday?\n",
      "OUT: [start] dónde estará usted el lunes [end]\n",
      "REF: [start] ¿Dónde estaréis el lunes? [end]\n",
      "BLEU: 0.6458 | Adjusted Score: 0.7692\n",
      "------------------------------------------------------------\n",
      "ENG: I constantly quarrel with my wife.\n",
      "OUT: [start] siempre he la discusión del que [UNK] con mi esposa [end]\n",
      "REF: [start] Me la paso discutiendo con mi esposa. [end]\n",
      "BLEU: 0.5849 | Adjusted Score: 0.6506\n",
      "------------------------------------------------------------\n",
      "ENG: What was Tom's reaction?\n",
      "OUT: [start] qué tal la espalda de tom [end]\n",
      "REF: [start] ¿Cuál fue la reacción de Tom? [end]\n",
      "BLEU: 0.5750 | Adjusted Score: 0.5750\n",
      "------------------------------------------------------------\n",
      "ENG: Lake Baikal in Russia is the deepest lake in the world.\n",
      "OUT: [start] el lago de lugar es de a los se los extranjeros en el mundo [end]\n",
      "REF: [start] El lago Baikal en Rusia es el lago más profundo del mundo. [end]\n",
      "BLEU: 0.4840 | Adjusted Score: 0.5812\n",
      "------------------------------------------------------------\n",
      "ENG: Washing your hands regularly is a good way to protect yourself from diseases.\n",
      "OUT: [start] lavadora que es una buena forma de tu lugar de tu lugar de ustedes se te [UNK] [end]\n",
      "REF: [start] Lavarse regularmente las manos es una buena manera de cuidarse de enfermedades. [end]\n",
      "BLEU: 0.4612 | Adjusted Score: 0.5298\n",
      "------------------------------------------------------------\n",
      "ENG: Who invented karaoke?\n",
      "OUT: [start] quién levantó más [UNK] [end]\n",
      "REF: [start] ¿Quién inventó el karaoke? [end]\n",
      "BLEU: 0.3117 | Adjusted Score: 0.4651\n",
      "------------------------------------------------------------\n",
      "ENG: If you spoke less and listened more, you'd definitely be able to learn something.\n",
      "OUT: [start] si habló menos lo [UNK] y escucha como fue capaz de aprender algo [end]\n",
      "REF: [start] Si hablases menos y escuchases más, definitivamente serías capaz de aprender algo. [end]\n",
      "BLEU: 0.6710 | Adjusted Score: 0.7042\n",
      "------------------------------------------------------------\n",
      "ENG: Everyone was drinking.\n",
      "OUT: [start] todos estaban a beber [end]\n",
      "REF: [start] Todos estaban bebiendo. [end]\n",
      "BLEU: 0.6340 | Adjusted Score: 0.7727\n",
      "------------------------------------------------------------\n",
      "ENG: I don't know why I bother coming here.\n",
      "OUT: [start] no sé por qué mismo me [UNK] [end]\n",
      "REF: [start] No sé por qué me molesto en venir aquí. [end]\n",
      "BLEU: 0.5857 | Adjusted Score: 0.5902\n",
      "------------------------------------------------------------\n",
      "ENG: Tom yelled Mary's name.\n",
      "OUT: [start] tom gritó el nombre de mary [end]\n",
      "REF: [start] Tom voceó el nombre de Mary. [end]\n",
      "BLEU: 0.9656 | Adjusted Score: 0.9656\n",
      "------------------------------------------------------------\n",
      "ENG: They're not happy.\n",
      "OUT: [start] ellos no están felices [end]\n",
      "REF: [start] Ellos no son felices. [end]\n",
      "BLEU: 0.7556 | Adjusted Score: 0.8372\n",
      "------------------------------------------------------------\n",
      "ENG: I want to know more about your country.\n",
      "OUT: [start] quiero saber más acerca de tu país [end]\n",
      "REF: [start] Quiero saber más sobre vuestro país. [end]\n",
      "BLEU: 0.6894 | Adjusted Score: 0.7143\n",
      "------------------------------------------------------------\n",
      "ENG: I once lived in Rome.\n",
      "OUT: [start] una vez he vivido en roma [end]\n",
      "REF: [start] Una vez viví en Roma. [end]\n",
      "BLEU: 0.7383 | Adjusted Score: 0.7391\n",
      "------------------------------------------------------------\n",
      "ENG: He is young.\n",
      "OUT: [start] Él es joven [end]\n",
      "REF: [start] Él es joven. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Why are you on this ship?\n",
      "OUT: [start] por qué estás en este barco [end]\n",
      "REF: [start] ¿Por qué estás en este barco? [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Where is it hidden?\n",
      "OUT: [start] dónde está herido [end]\n",
      "REF: [start] ¿Dónde se oculta? [end]\n",
      "BLEU: 0.4350 | Adjusted Score: 0.4706\n",
      "------------------------------------------------------------\n",
      "ENG: He wasn't happy in spite of all his wealth.\n",
      "OUT: [start] no era a pesar de que todos sus hijos [UNK] [end]\n",
      "REF: [start] No era feliz a pesar de toda su fortuna. [end]\n",
      "BLEU: 0.6895 | Adjusted Score: 0.6895\n",
      "------------------------------------------------------------\n",
      "ENG: You don't need to do that.\n",
      "OUT: [start] no necesitas hacerlo [end]\n",
      "REF: [start] No tenéis que hacer eso. [end]\n",
      "BLEU: 0.2233 | Adjusted Score: 0.5455\n",
      "------------------------------------------------------------\n",
      "ENG: You're quite smart.\n",
      "OUT: [start] eres muy listo [end]\n",
      "REF: [start] Eres bastante listo. [end]\n",
      "BLEU: 0.5952 | Adjusted Score: 0.5952\n",
      "------------------------------------------------------------\n",
      "ENG: I haven't dismissed you yet.\n",
      "OUT: [start] todavía no he siendo el el el el siendo el ese siendo el ese siendo es herido todavía [end]\n",
      "REF: [start] Aún no te he despedido. [end]\n",
      "BLEU: 0.3026 | Adjusted Score: 0.3148\n",
      "------------------------------------------------------------\n",
      "ENG: That guy has a screw loose!\n",
      "OUT: [start] ese tipo me duele él [end]\n",
      "REF: [start] ¡Ese tipo tiene suelto un tornillo! [end]\n",
      "BLEU: 0.4493 | Adjusted Score: 0.5455\n",
      "------------------------------------------------------------\n",
      "ENG: I can't figure out how to solve the puzzle.\n",
      "OUT: [start] no puedo averiguar cómo se se se se se se se se puede salir [end]\n",
      "REF: [start] No puedo averiguar como resolver el rompecabezas. [end]\n",
      "BLEU: 0.4241 | Adjusted Score: 0.5926\n",
      "------------------------------------------------------------\n",
      "ENG: You'll have to overcome a few difficulties.\n",
      "OUT: [start] tendrás que llevar un error se [UNK] [end]\n",
      "REF: [start] Deberás superar algunos inconvenientes. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.4348\n",
      "------------------------------------------------------------\n",
      "ENG: I am glad it was someone else who got it.\n",
      "OUT: [start] me alegro de que fuera otra persona que era más [end]\n",
      "REF: [start] Me alegra que lo haya recibido otro. [end]\n",
      "BLEU: 0.3502 | Adjusted Score: 0.4578\n",
      "------------------------------------------------------------\n",
      "ENG: Do you care what they think?\n",
      "OUT: [start] te importa lo que ellos creen [end]\n",
      "REF: [start] ¿Te importa lo que ellos piensan? [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: He is a tennis player.\n",
      "OUT: [start] Él es un jugador de tenis [end]\n",
      "REF: [start] Él es jugador de tenis. [end]\n",
      "BLEU: 0.9311 | Adjusted Score: 0.9311\n",
      "------------------------------------------------------------\n",
      "ENG: He was deserted by his friends.\n",
      "OUT: [start] Él fue desierta por sus amigos [end]\n",
      "REF: [start] Él fue abandonado por sus amigos. [end]\n",
      "BLEU: 0.9311 | Adjusted Score: 0.9311\n",
      "------------------------------------------------------------\n",
      "ENG: The sooner, the better.\n",
      "OUT: [start] cuanto antes mejor [end]\n",
      "REF: [start] Cuanto antes mejor. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: You can make your own.\n",
      "OUT: [start] podés hacer tus propia [end]\n",
      "REF: [start] Puedes hacerte uno propio. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.6667\n",
      "------------------------------------------------------------\n",
      "ENG: Let's have a contest. The side to come up with the worst insult wins.\n",
      "OUT: [start] vamos a [UNK] un niño para venir con el peor venido por la peor valiente [end]\n",
      "REF: [start] Hagamos un concurso. Aquel bando al que se le ocurra el peor insulto, gana. [end]\n",
      "BLEU: 0.3809 | Adjusted Score: 0.4789\n",
      "------------------------------------------------------------\n",
      "ENG: Come along with us.\n",
      "OUT: [start] ven con nosotros [end]\n",
      "REF: [start] Vengan con nosotras. [end]\n",
      "BLEU: 0.4350 | Adjusted Score: 0.7778\n",
      "------------------------------------------------------------\n",
      "ENG: You opened the wrong box.\n",
      "OUT: [start] abrió la caja equivocado [end]\n",
      "REF: [start] Abriste la caja incorrecta. [end]\n",
      "BLEU: 0.6340 | Adjusted Score: 0.6340\n",
      "------------------------------------------------------------\n",
      "ENG: What time's your train?\n",
      "OUT: [start] qué el tren [end]\n",
      "REF: [start] ¿A qué hora es tu tren? [end]\n",
      "BLEU: 0.2190 | Adjusted Score: 0.5882\n",
      "------------------------------------------------------------\n",
      "ENG: It isn't possible to clear the snow from every road.\n",
      "OUT: [start] no es posible dejar que vaya a la nieve todos los dólares [end]\n",
      "REF: [start] Es imposible quitar la nieve en todas las carreteras. [end]\n",
      "BLEU: 0.4047 | Adjusted Score: 0.6364\n",
      "------------------------------------------------------------\n",
      "ENG: Don't you know that he passed away two years ago?\n",
      "OUT: [start] no sabes que se lo pasó hace dos años [end]\n",
      "REF: [start] ¿No sabes que él falleció hace dos años? [end]\n",
      "BLEU: 0.8145 | Adjusted Score: 0.8145\n",
      "------------------------------------------------------------\n",
      "ENG: These are great.\n",
      "OUT: [start] estas son grandes [end]\n",
      "REF: [start] Éstos son geniales. [end]\n",
      "BLEU: 0.4350 | Adjusted Score: 0.6667\n",
      "------------------------------------------------------------\n",
      "ENG: One thousand buildings lay in ruins.\n",
      "OUT: [start] mil pies se quedaron en casas [end]\n",
      "REF: [start] Mil edificios están en ruinas. [end]\n",
      "BLEU: 0.4203 | Adjusted Score: 0.4746\n",
      "------------------------------------------------------------\n",
      "ENG: Tom blames himself for what happened to Mary.\n",
      "OUT: [start] tom se culpa por lo que pasó a mary [end]\n",
      "REF: [start] Tom se culpa a sí mismo por lo que pasó a María. [end]\n",
      "BLEU: 0.7596 | Adjusted Score: 0.7711\n",
      "------------------------------------------------------------\n",
      "ENG: The teacher listened attentively to my explanation.\n",
      "OUT: [start] el profesor escuchó con atención a mi explicación [end]\n",
      "REF: [start] El profesor escuchó atentamente mi explicación. [end]\n",
      "BLEU: 0.7485 | Adjusted Score: 0.8125\n",
      "------------------------------------------------------------\n",
      "ENG: He bought a dress for her.\n",
      "OUT: [start] Él se compró un vestido para ella [end]\n",
      "REF: [start] Él le compró un vestido a ella. [end]\n",
      "BLEU: 0.7594 | Adjusted Score: 0.9062\n",
      "------------------------------------------------------------\n",
      "ENG: I'm not interested in a serious relationship.\n",
      "OUT: [start] no me interesa una relación en serio [end]\n",
      "REF: [start] No estoy interesada en una relación seria. [end]\n",
      "BLEU: 0.5944 | Adjusted Score: 0.7692\n",
      "------------------------------------------------------------\n",
      "ENG: Something is not right.\n",
      "OUT: [start] algo no está en derecho [end]\n",
      "REF: [start] Algo no va bien. [end]\n",
      "BLEU: 0.5488 | Adjusted Score: 0.5488\n",
      "------------------------------------------------------------\n",
      "ENG: You must not yield to temptation.\n",
      "OUT: [start] no debes muy pronto es [UNK] [end]\n",
      "REF: [start] No debes ceder a la tentación. [end]\n",
      "BLEU: 0.4493 | Adjusted Score: 0.4493\n",
      "------------------------------------------------------------\n",
      "ENG: I love the way you dress.\n",
      "OUT: [start] me encanta [UNK] [end]\n",
      "REF: [start] Me gusta como te vestís. [end]\n",
      "BLEU: 0.1155 | Adjusted Score: 0.2941\n",
      "------------------------------------------------------------\n",
      "ENG: I didn't take any books from the library.\n",
      "OUT: [start] no me habido ningún libro de la biblioteca [end]\n",
      "REF: [start] Yo no saqué ningún libro de la biblioteca. [end]\n",
      "BLEU: 0.9128 | Adjusted Score: 0.9128\n",
      "------------------------------------------------------------\n",
      "ENG: He has four mobile phones.\n",
      "OUT: [start] Él tiene cuatro [UNK] [end]\n",
      "REF: [start] Él tiene cuatro móviles. [end]\n",
      "BLEU: 0.9045 | Adjusted Score: 0.9045\n",
      "------------------------------------------------------------\n",
      "ENG: I really wasn't expecting that from you.\n",
      "OUT: [start] realmente no esperaba eso de vos [end]\n",
      "REF: [start] La verdad es que no esperaba eso de ti. [end]\n",
      "BLEU: 0.5348 | Adjusted Score: 0.6761\n",
      "------------------------------------------------------------\n",
      "ENG: Are all these books yours?\n",
      "OUT: [start] todos estos son estos libros [end]\n",
      "REF: [start] ¿Son tuyos todos estos libros? [end]\n",
      "BLEU: 0.8453 | Adjusted Score: 0.8453\n",
      "------------------------------------------------------------\n",
      "ENG: A promise is a promise.\n",
      "OUT: [start] una promesa es una promesa [end]\n",
      "REF: [start] Promesas son promesas. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.7083\n",
      "------------------------------------------------------------\n",
      "ENG: Tom was my teacher.\n",
      "OUT: [start] tom fue mi profesor [end]\n",
      "REF: [start] Tom fue mi profesor. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: You're my enemy.\n",
      "OUT: [start] eres mi enemigo [end]\n",
      "REF: [start] Usted es mi enemiga. [end]\n",
      "BLEU: 0.3117 | Adjusted Score: 0.7429\n",
      "------------------------------------------------------------\n",
      "ENG: We closed early.\n",
      "OUT: [start] nos se [UNK] temprano [end]\n",
      "REF: [start] Cerramos temprano. [end]\n",
      "BLEU: 0.5739 | Adjusted Score: 0.6471\n",
      "------------------------------------------------------------\n",
      "ENG: It doesn't work so well because the batteries are running down.\n",
      "OUT: [start] no funciona tan bien porque las [UNK] porque están corriendo [end]\n",
      "REF: [start] No funciona muy bien porque las pilas se están agotando. [end]\n",
      "BLEU: 0.6657 | Adjusted Score: 0.7387\n",
      "------------------------------------------------------------\n",
      "ENG: Are they brothers?\n",
      "OUT: [start] son hermanos [end]\n",
      "REF: [start] ¿Son hermanos? [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: He is doing penance.\n",
      "OUT: [start] Él está haciendo [UNK] [end]\n",
      "REF: [start] Está haciendo penitencia. [end]\n",
      "BLEU: 0.7888 | Adjusted Score: 0.7888\n",
      "------------------------------------------------------------\n",
      "ENG: Tom doesn't know what Mary wants him to buy her for her birthday.\n",
      "OUT: [start] tom no sabe qué quiere que mary le compre para su cumpleaños [end]\n",
      "REF: [start] Tom no sabe lo que Mary quiere que él le compre para su cumpleaños. [end]\n",
      "BLEU: 0.8828 | Adjusted Score: 0.8828\n",
      "------------------------------------------------------------\n",
      "ENG: We're all from Boston.\n",
      "OUT: [start] todos somos de boston [end]\n",
      "REF: [start] Todos somos de Boston. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: If you don't want to talk about it, that's okay.\n",
      "OUT: [start] si no quieres hablar de eso tienes de acuerdo [end]\n",
      "REF: [start] Si no quieres hablar de ello, no pasa nada. [end]\n",
      "BLEU: 0.7783 | Adjusted Score: 0.7783\n",
      "------------------------------------------------------------\n",
      "ENG: Why he killed himself is still a mystery.\n",
      "OUT: [start] por qué él se mató el siendo un siendo [UNK] [end]\n",
      "REF: [start] Sigue siendo un misterio el porqué él se suicidó. [end]\n",
      "BLEU: 0.6204 | Adjusted Score: 0.6204\n",
      "------------------------------------------------------------\n",
      "ENG: Don't let it scare you.\n",
      "OUT: [start] no dejes que te [UNK] [end]\n",
      "REF: [start] No consientas que te atemorice. [end]\n",
      "BLEU: 0.5885 | Adjusted Score: 0.5885\n",
      "------------------------------------------------------------\n",
      "ENG: If I were Tom, I would've punched Mary in the face.\n",
      "OUT: [start] si yo fuera a tom le habría [UNK] a maría en la cara [end]\n",
      "REF: [start] Si yo fuese Tom le habría metido un vergajazo a María en la cara. [end]\n",
      "BLEU: 0.8179 | Adjusted Score: 0.8179\n",
      "------------------------------------------------------------\n",
      "ENG: There's a spider in the shower.\n",
      "OUT: [start] hay una bolsa de la ducha [end]\n",
      "REF: [start] Hay una araña en la ducha. [end]\n",
      "BLEU: 0.7383 | Adjusted Score: 0.7451\n",
      "------------------------------------------------------------\n",
      "ENG: I always keep promises.\n",
      "OUT: [start] siempre llevo promesas [end]\n",
      "REF: [start] Yo siempre mantengo las promesas. [end]\n",
      "BLEU: 0.3056 | Adjusted Score: 0.6909\n",
      "------------------------------------------------------------\n",
      "ENG: I like that job.\n",
      "OUT: [start] me gusta ese trabajo [end]\n",
      "REF: [start] Me gusta ese trabajo. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: I am happy to see you again.\n",
      "OUT: [start] estoy feliz de verte de nuevo [end]\n",
      "REF: [start] Me alegro de verte otra vez. [end]\n",
      "BLEU: 0.4943 | Adjusted Score: 0.5263\n",
      "------------------------------------------------------------\n",
      "ENG: Let me finish.\n",
      "OUT: [start] déjame terminar [end]\n",
      "REF: [start] Déjame terminar. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Tom didn't want to get up so early.\n",
      "OUT: [start] tom no quería levantarte tan pronto [end]\n",
      "REF: [start] Tom no quería levantarse tan temprano. [end]\n",
      "BLEU: 0.7702 | Adjusted Score: 0.8493\n",
      "------------------------------------------------------------\n",
      "ENG: My father stopped smoking.\n",
      "OUT: [start] mi padre dejó de fumar [end]\n",
      "REF: [start] Mi padre ha dejado de fumar. [end]\n",
      "BLEU: 0.6921 | Adjusted Score: 0.8000\n",
      "------------------------------------------------------------\n",
      "ENG: It's the same hat.\n",
      "OUT: [start] es el mismo sombrero [end]\n",
      "REF: [start] Es el mismo sombrero. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: He loves her.\n",
      "OUT: [start] Él la quiere [end]\n",
      "REF: [start] Él la quiere. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: I have to organize my schedule before the end of the month.\n",
      "OUT: [start] tengo que [UNK] mi derecho a fin de mes [end]\n",
      "REF: [start] Tengo que organizar mi horario antes de fin de mes. [end]\n",
      "BLEU: 0.6307 | Adjusted Score: 0.6588\n",
      "------------------------------------------------------------\n",
      "ENG: He must be Tom's brother.\n",
      "OUT: [start] Él debe de ser el hermano de tom [end]\n",
      "REF: [start] Debe de ser el hermano de Tom. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Cats catch mice.\n",
      "OUT: [start] los gatos conocen los pies [end]\n",
      "REF: [start] Los gatos atrapan ratones. [end]\n",
      "BLEU: 0.5488 | Adjusted Score: 0.5488\n",
      "------------------------------------------------------------\n",
      "ENG: Isn't that an English book?\n",
      "OUT: [start] ese no es un libro de inglés [end]\n",
      "REF: [start] ¿No es eso un libro de inglés? [end]\n",
      "BLEU: 0.9898 | Adjusted Score: 0.9898\n",
      "------------------------------------------------------------\n",
      "ENG: I asked Tom if he could have it ready by 2:30.\n",
      "OUT: [start] le pregunté a tom si podía estar listo para las 230 [end]\n",
      "REF: [start] Le pregunté a Tom si lo podía tener listo a las 2:30. [end]\n",
      "BLEU: 0.8186 | Adjusted Score: 0.8269\n",
      "------------------------------------------------------------\n",
      "ENG: Tom was wearing his pajamas when he opened the door.\n",
      "OUT: [start] tom llevaba puesto su cuadro cuando abrió la puerta [end]\n",
      "REF: [start] Tom estaba en pijamas cuando abrió la puerta. [end]\n",
      "BLEU: 0.7106 | Adjusted Score: 0.7106\n",
      "------------------------------------------------------------\n",
      "ENG: Take that off your head.\n",
      "OUT: [start] toma la cabeza tu cabeza [end]\n",
      "REF: [start] Sácate eso de la cabeza. [end]\n",
      "BLEU: 0.5488 | Adjusted Score: 0.5488\n",
      "------------------------------------------------------------\n",
      "ENG: You must study English every day.\n",
      "OUT: [start] debes estudiar inglés todos los días [end]\n",
      "REF: [start] Debes estudiar inglés todos los días. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: She kept crying all night long.\n",
      "OUT: [start] ella siguió llorando toda la noche [end]\n",
      "REF: [start] Ella estuvo llorando toda la noche. [end]\n",
      "BLEU: 0.9656 | Adjusted Score: 0.9656\n",
      "------------------------------------------------------------\n",
      "ENG: What do you say to a beer?\n",
      "OUT: [start] qué dices que dices no es cerveza [end]\n",
      "REF: [start] ¿Qué tal una chela? [end]\n",
      "BLEU: 0.3268 | Adjusted Score: 0.3846\n",
      "------------------------------------------------------------\n",
      "ENG: The percentage of carbohydrates in animal cells is approximately 6 percent.\n",
      "OUT: [start] la [UNK] de la [UNK] de la [UNK] alrededor de la [UNK] en las seis [end]\n",
      "REF: [start] El porcentaje de carbohidratos en las célula animal es de aproximadamente el seis por ciento. [end]\n",
      "BLEU: 0.3527 | Adjusted Score: 0.4460\n",
      "------------------------------------------------------------\n",
      "ENG: What is my room number?\n",
      "OUT: [start] cuál es mi número de mi habitación [end]\n",
      "REF: [start] ¿Cuál es mi número de habitación? [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Tom has long hair.\n",
      "OUT: [start] tom tiene el pelo largo [end]\n",
      "REF: [start] Tomás tiene el pelo largo. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Is it here?\n",
      "OUT: [start] está aquí [end]\n",
      "REF: [start] ¿Aquí? [end]\n",
      "BLEU: 0.6898 | Adjusted Score: 0.6898\n",
      "------------------------------------------------------------\n",
      "ENG: My neighbor complained about the noise.\n",
      "OUT: [start] mi vecino se la cabeza con el ruido [end]\n",
      "REF: [start] Mi vecina se quejó por el ruido. [end]\n",
      "BLEU: 0.5491 | Adjusted Score: 0.6866\n",
      "------------------------------------------------------------\n",
      "ENG: I can't remember what her name is.\n",
      "OUT: [start] no puedo recordar cómo se llama [end]\n",
      "REF: [start] No me puedo acordar de su nombre. [end]\n",
      "BLEU: 0.3558 | Adjusted Score: 0.5938\n",
      "------------------------------------------------------------\n",
      "ENG: We're not your enemies.\n",
      "OUT: [start] no somos tus ningún enemigo [end]\n",
      "REF: [start] No somos tus enemigos. [end]\n",
      "BLEU: 0.7879 | Adjusted Score: 0.7879\n",
      "------------------------------------------------------------\n",
      "ENG: I'm sorry I cannot go with you.\n",
      "OUT: [start] lamento no haber ido contigo [end]\n",
      "REF: [start] Lo siento, no puedo ir contigo. [end]\n",
      "BLEU: 0.3726 | Adjusted Score: 0.6441\n",
      "------------------------------------------------------------\n",
      "ENG: I haven't given them to Tom yet.\n",
      "OUT: [start] no les he dicho que tom no les dio a nadie [end]\n",
      "REF: [start] Yo no se los he dado a Tom todavía. [end]\n",
      "BLEU: 0.4277 | Adjusted Score: 0.5195\n",
      "------------------------------------------------------------\n",
      "ENG: I don't know where she lives.\n",
      "OUT: [start] no sé dónde vive ella [end]\n",
      "REF: [start] No sé dónde vive ella. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: She is accustomed to doing her homework before dinner.\n",
      "OUT: [start] ella está acostumbrado a hacer la cena antes de la cena [end]\n",
      "REF: [start] Ella comúnmente hace sus tareas antes de cenar. [end]\n",
      "BLEU: 0.4199 | Adjusted Score: 0.5882\n",
      "------------------------------------------------------------\n",
      "ENG: I heard the girl crying for help.\n",
      "OUT: [start] escuché a la niña en la ayuda de [UNK] [end]\n",
      "REF: [start] Oí a la chica gritar por ayuda. [end]\n",
      "BLEU: 0.4888 | Adjusted Score: 0.5079\n",
      "------------------------------------------------------------\n",
      "ENG: It's raining again!\n",
      "OUT: [start] está lloviendo otra vez [end]\n",
      "REF: [start] ¡Está lloviendo otra vez! [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: The teacher told me to stand up.\n",
      "OUT: [start] el profesor me dijo que se [UNK] [end]\n",
      "REF: [start] El profesor me pidió que me levantase. [end]\n",
      "BLEU: 0.6519 | Adjusted Score: 0.7188\n",
      "------------------------------------------------------------\n",
      "ENG: How do you intend to fix this?\n",
      "OUT: [start] cómo [UNK] arreglar esto [end]\n",
      "REF: [start] ¿Cómo pretendes arreglar esto? [end]\n",
      "BLEU: 0.6821 | Adjusted Score: 0.7347\n",
      "------------------------------------------------------------\n",
      "ENG: I need to talk to both of you.\n",
      "OUT: [start] necesito hablar contigo ambos [end]\n",
      "REF: [start] Necesito hablar con ustedes dos. [end]\n",
      "BLEU: 0.4937 | Adjusted Score: 0.7213\n",
      "------------------------------------------------------------\n",
      "ENG: Has Tom told Mary?\n",
      "OUT: [start] le ha dicho a tom [end]\n",
      "REF: [start] ¿Se lo ha dicho Tom a Mary? [end]\n",
      "BLEU: 0.4977 | Adjusted Score: 0.5909\n",
      "------------------------------------------------------------\n",
      "ENG: They were put in prison.\n",
      "OUT: [start] ellos estaban en prisión [end]\n",
      "REF: [start] Ellos fueron puestos en prisión. [end]\n",
      "BLEU: 0.5885 | Adjusted Score: 0.6786\n",
      "------------------------------------------------------------\n",
      "ENG: I have more skirts than my big sister.\n",
      "OUT: [start] tengo más falda que mi hermana [end]\n",
      "REF: [start] Tengo más faldas que mi hermana mayor. [end]\n",
      "BLEU: 0.7882 | Adjusted Score: 0.8529\n",
      "------------------------------------------------------------\n",
      "ENG: Don't say that.\n",
      "OUT: [start] no digas eso [end]\n",
      "REF: [start] No digas eso. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: It was a nice day so we went fishing.\n",
      "OUT: [start] fue un buen día para que la pescar nos fui de pescar [end]\n",
      "REF: [start] Era un buen día así que fuimos a pescar. [end]\n",
      "BLEU: 0.5367 | Adjusted Score: 0.6522\n",
      "------------------------------------------------------------\n",
      "ENG: Is it right for a doctor to decide when someone should die?\n",
      "OUT: [start] es que tiene derecho a un médico cuando alguien se se se se se se se se me para para\n",
      "REF: [start] ¿Es correcto que un médico decida cuándo debería morir alguien? [end]\n",
      "BLEU: 0.3865 | Adjusted Score: 0.4218\n",
      "------------------------------------------------------------\n",
      "ENG: Don't do anything you'll regret.\n",
      "OUT: [start] no hagas nada de lo que sea [end]\n",
      "REF: [start] No hagas nada de lo que te arrepentirías. [end]\n",
      "BLEU: 0.9565 | Adjusted Score: 0.9565\n",
      "------------------------------------------------------------\n",
      "ENG: I want Tom put in prison.\n",
      "OUT: [start] quiero que tom puso en prisión [end]\n",
      "REF: [start] Quiero que metan a Tom a la carcel. [end]\n",
      "BLEU: 0.4120 | Adjusted Score: 0.5231\n",
      "------------------------------------------------------------\n",
      "ENG: You need it.\n",
      "OUT: [start] lo necesitas [end]\n",
      "REF: [start] Lo necesitáis. [end]\n",
      "BLEU: 0.6898 | Adjusted Score: 0.7692\n",
      "------------------------------------------------------------\n",
      "ENG: I'm not a bad person.\n",
      "OUT: [start] no soy una mala persona [end]\n",
      "REF: [start] No soy una mala persona. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: I'm sorry to disturb you while you're talking.\n",
      "OUT: [start] lamento decirte [end]\n",
      "REF: [start] Lamento molestarte mientras estás conversando. [end]\n",
      "BLEU: 0.1155 | Adjusted Score: 0.3934\n",
      "------------------------------------------------------------\n",
      "ENG: Write your name in capital letters.\n",
      "OUT: [start] escribe tus cartas [UNK] [end]\n",
      "REF: [start] Escriba su nombre en mayúsculas. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.4400\n",
      "------------------------------------------------------------\n",
      "ENG: I understand what he's trying to say.\n",
      "OUT: [start] entiendo lo que está intentando decir [end]\n",
      "REF: [start] Entiendo lo que está intentando decir. [end]\n",
      "BLEU: 1.0000 | Adjusted Score: 1.0000\n",
      "------------------------------------------------------------\n",
      "ENG: Call an ambulance.\n",
      "OUT: [start] llama una [UNK] [end]\n",
      "REF: [start] Llama a una ambulancia. [end]\n",
      "BLEU: 0.2787 | Adjusted Score: 0.5000\n",
      "------------------------------------------------------------\n",
      "ENG: I am very thankful to you for your advice.\n",
      "OUT: [start] estoy muy agradecido de tu consejo por tu consejo [end]\n",
      "REF: [start] Te estoy muy agradecido por tu consejo. [end]\n",
      "BLEU: 0.8145 | Adjusted Score: 0.8145\n",
      "------------------------------------------------------------\n",
      "ENG: He aimed at the bird.\n",
      "OUT: [start] Él le echó al pájaro [end]\n",
      "REF: [start] Él le apuntó al pájaro. [end]\n",
      "BLEU: 0.8453 | Adjusted Score: 0.8453\n",
      "------------------------------------------------------------\n",
      "ENG: I usually have dessert after dinner.\n",
      "OUT: [start] normalmente me [UNK] el postre [end]\n",
      "REF: [start] Suelo tomar postre después de cenar. [end]\n",
      "BLEU: 0.2349 | Adjusted Score: 0.3607\n",
      "------------------------------------------------------------\n",
      "ENG: Which house is his?\n",
      "OUT: [start] qué casa es su casa [end]\n",
      "REF: [start] ¿Cuál casa es la suya? [end]\n",
      "BLEU: 0.5488 | Adjusted Score: 0.6341\n",
      "------------------------------------------------------------\n",
      "ENG: People shouldn't abuse animals.\n",
      "OUT: [start] la gente no debe saber la lengua [end]\n",
      "REF: [start] Las personas no deberían abusar de los animales. [end]\n",
      "BLEU: 0.2833 | Adjusted Score: 0.5250\n",
      "------------------------------------------------------------\n",
      "ENG: The press conference is scheduled to begin one hour from now.\n",
      "OUT: [start] la conferencia acaba de conferencia empieza a [UNK] de una hora [end]\n",
      "REF: [start] La conferencia de prensa está agendada para dar comienzo dentro de una hora. [end]\n",
      "BLEU: 0.5124 | Adjusted Score: 0.5970\n",
      "------------------------------------------------------------\n",
      "ENG: I'll lend you the book as soon as I'm done reading it.\n",
      "OUT: [start] te daré el libro tan pronto como lo haya hecho [end]\n",
      "REF: [start] Te voy a prestar el libro apenas termine de leerlo. [end]\n",
      "BLEU: 0.4381 | Adjusted Score: 0.4948\n",
      "------------------------------------------------------------\n",
      "ENG: You've made me what I am.\n",
      "OUT: [start] me has hecho lo que yo [end]\n",
      "REF: [start] Tú me has hecho lo que soy. [end]\n",
      "BLEU: 0.9081 | Adjusted Score: 0.9081\n",
      "------------------------------------------------------------\n",
      "ENG: We made inquiries into his past.\n",
      "OUT: [start] hemos hecho preguntas [UNK] a su pasado [end]\n",
      "REF: [start] Hicimos averiguaciones en su pasado. [end]\n",
      "BLEU: 0.4943 | Adjusted Score: 0.6000\n",
      "------------------------------------------------------------\n",
      "ENG: Did you enjoy your winter holidays?\n",
      "OUT: [start] te gustó tus vacaciones de invierno [end]\n",
      "REF: [start] ¿Disfrutaste tus vacaciones de invierno? [end]\n",
      "BLEU: 0.8817 | Adjusted Score: 0.8817\n",
      "------------------------------------------------------------\n",
      "ENG: Think about it.\n",
      "OUT: [start] [UNK] [end]\n",
      "REF: [start] Piénsalo. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.0000\n",
      "------------------------------------------------------------\n",
      "ENG: I've always trusted you.\n",
      "OUT: [start] siempre he confianza en vos [end]\n",
      "REF: [start] Siempre he confiado en ti. [end]\n",
      "BLEU: 0.6458 | Adjusted Score: 0.7547\n",
      "------------------------------------------------------------\n",
      "ENG: I was born in 1972.\n",
      "OUT: [start] perdí el la estación de [UNK] [end]\n",
      "REF: [start] Nací en 1972. [end]\n",
      "BLEU: 0.0000 | Adjusted Score: 0.2778\n",
      "------------------------------------------------------------\n",
      "\n",
      "Average BLEU over these 150 samples: 0.6421\n",
      "Adjusted Average Score (BLEU + Levenshtein): 0.7271\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import re\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import matplotlib.pyplot as plt\n",
    "from Levenshtein import ratio  # Requires `pip install python-Levenshtein`\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Use stronger smoothing\n",
    "smoothie = SmoothingFunction().method7  \n",
    "\n",
    "# BLEU weights: Favor unigrams (BLEU-1) and bigrams (BLEU-2)\n",
    "default_weights = (0.7, 0.3, 0.0, 0.0)  \n",
    "short_sentence_weights = (1.0, 0.0, 0.0, 0.0)  # BLEU-1 for short cases\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Lowercase and remove punctuation for better BLEU matching.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "def get_reference_spanish(eng_sentence, test_pairs):\n",
    "    \"\"\"Finds the correct Spanish reference for an English sentence.\"\"\"\n",
    "    for eng, spa in test_pairs:\n",
    "        if eng == eng_sentence:\n",
    "            return spa\n",
    "    return None  # Skip if no match found\n",
    "\n",
    "spa_vocab = spa_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    \"\"\"Generates a Spanish translation for an English sentence using the model.\"\"\"\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            {\n",
    "                \"encoder_inputs\": tokenized_input_sentence,\n",
    "                \"decoder_inputs\": tokenized_target_sentence,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        sampled_token_index = ops.convert_to_numpy(\n",
    "            ops.argmax(predictions[0, i, :])\n",
    "        ).item(0)\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "\n",
    "bleu_scores = []\n",
    "adjusted_scores = []\n",
    "\n",
    "for _ in range(150):\n",
    "    # 1) Pick a random English sentence from the test set\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    # 2) Get the model's translation\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    # 3) Retrieve the reference Spanish text from test_pairs\n",
    "    reference_spa = get_reference_spanish(input_sentence, test_pairs)\n",
    "    \n",
    "    # Print the pair (optional)\n",
    "    print(f\"ENG: {input_sentence}\")\n",
    "    print(f\"OUT: {translated}\")\n",
    "    \n",
    "    if reference_spa is not None:\n",
    "        print(f\"REF: {reference_spa}\")\n",
    "        \n",
    "        # 4) Clean up translations: Remove [start]/[end] and `[UNK]`\n",
    "        candidate_clean = translated.replace(\"[start]\", \"\").replace(\"[end]\", \"\").replace(\"[UNK]\", \"\").strip()\n",
    "        reference_clean = reference_spa.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip()\n",
    "\n",
    "        # 5) Normalize text (lowercase + remove punctuation)\n",
    "        candidate_tokens = normalize_text(candidate_clean).split()\n",
    "        reference_tokens = normalize_text(reference_clean).split()\n",
    "\n",
    "        # 6) Handle BLEU for short sentences differently\n",
    "        if len(reference_tokens) <= 2:  # If sentence is very short, use BLEU-1\n",
    "            weights = short_sentence_weights\n",
    "        else:\n",
    "            weights = default_weights\n",
    "\n",
    "        # 7) Compute BLEU score (if valid candidate exists)\n",
    "        if candidate_tokens:\n",
    "            score = sentence_bleu([reference_tokens], candidate_tokens, weights=weights, smoothing_function=smoothie)\n",
    "            score = min(1.0, score)  # **Ensure BLEU is capped at 1.0**\n",
    "        else:\n",
    "            score = 0.0  # Empty translations get 0 BLEU\n",
    "        \n",
    "        bleu_scores.append(score)\n",
    "\n",
    "        # 8) If BLEU score is too low, use Levenshtein ratio as a fallback\n",
    "        levenshtein_sim = ratio(candidate_clean, reference_clean)  # Similarity between full sentences\n",
    "        adjusted_score = max(score, levenshtein_sim)  # Keep the best of BLEU or similarity\n",
    "        adjusted_score = min(1.0, adjusted_score)  # **Cap adjusted score at 1.0**\n",
    "        adjusted_scores.append(adjusted_score)\n",
    "\n",
    "        print(f\"BLEU: {score:.4f} | Adjusted Score: {adjusted_score:.4f}\")\n",
    "    else:\n",
    "        print(\"No reference found. (Skipping BLEU for this sample)\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Once all 150 samples are done, compute and print average BLEU\n",
    "if bleu_scores:\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_adjusted_bleu = sum(adjusted_scores) / len(adjusted_scores)\n",
    "    print(f\"\\nAverage BLEU over these 150 samples: {avg_bleu:.4f}\")\n",
    "    print(f\"Adjusted Average Score (BLEU + Levenshtein): {avg_adjusted_bleu:.4f}\")\n",
    "    \n",
    "    # Optionally, plot a histogram of BLEU scores\n",
    "    plt.hist(adjusted_scores, bins=20, edgecolor='black')\n",
    "    plt.title(\"Adjusted BLEU Score Distribution (150 Samples)\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No BLEU scores were computed (no references matched).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
